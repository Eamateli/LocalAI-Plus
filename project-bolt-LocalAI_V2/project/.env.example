# LocalAI+ Configuration

# Basic Settings
DEBUG=true
SECRET_KEY=your-secret-key-change-in-production

# Database Settings
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=localai_plus
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

# Redis Settings
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Qdrant Settings
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=

# Ollama Settings
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=300

# vLLM Settings
VLLM_HOST=http://localhost:8001
VLLM_TIMEOUT=300

# Authentication Settings
ACCESS_TOKEN_EXPIRE_MINUTES=43200
ALGORITHM=HS256

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Model Settings
MAX_MODELS_IN_MEMORY=3
MODEL_CACHE_TTL=3600
MAX_CONTEXT_LENGTH=32768
MAX_TOKENS=4096

# Feature Flags
ENABLE_FUNCTION_CALLING=true
ENABLE_CODE_EXECUTION=true

# Docker Settings (for code execution)
DOCKER_TIMEOUT=30
DOCKER_MEMORY_LIMIT=512m
DOCKER_CPU_LIMIT=1.0

# Frontend Settings
VITE_API_URL=http://localhost:8000/v1
VITE_WS_URL=ws://localhost:8000/ws